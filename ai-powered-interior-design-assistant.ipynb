{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1399134,"sourceType":"datasetVersion","datasetId":817307}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, UpSampling2D\nfrom tensorflow.keras.models import Model\nfrom transformers import pipeline\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Dataset path\nDATASET_PATH = '/kaggle/input/interior-design/resized_images'\nIMG_SIZE = 128  # Standardize image size\nEPOCHS = 200\nBATCH_SIZE = 32\nSAVE_PATH = \"/kaggle/working/interior_design_gan_model.h5\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Helper function to load images\ndef load_images(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img_path = os.path.join(folder, filename)\n        img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n        img = img_to_array(img) / 255.0\n        images.append(img)\n    return np.array(images)\n\n# Load dataset\nprint(\"Loading dataset...\")\nimages = load_images(DATASET_PATH)\nprint(f\"Loaded {images.shape[0]} images with shape {images.shape[1:]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generator model\ndef build_generator():\n    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(inputs)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = UpSampling2D((2, 2))(x)\n    outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n    return Model(inputs, outputs)\n\n# Discriminator model\ndef build_discriminator():\n    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = Conv2D(64, (3, 3), padding='same', strides=(2, 2))(inputs)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), padding='same', strides=(2, 2))(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Flatten()(x)\n    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    return Model(inputs, outputs)\n\n# Build GAN\ngenerator = build_generator()\ndiscriminator = build_discriminator()\ndiscriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Combined GAN model\ndiscriminator.trainable = False\ngan_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)\ngan.compile(optimizer='adam', loss='binary_crossentropy')\n\nprint(\"Generator and Discriminator models built.\")\ngenerator.summary()\ndiscriminator.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to train GAN\ndef train_gan(generator, discriminator, gan, images, epochs, batch_size):\n    for epoch in range(epochs):\n        idx = np.random.randint(0, images.shape[0], batch_size)\n        real_images = images[idx]\n        fake_images = generator.predict(real_images)\n\n        # Train discriminator\n        d_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n        d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        # Train generator\n        g_loss = gan.train_on_batch(real_images, np.ones((batch_size, 1)))\n\n        if epoch % 10 == 0:\n            print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n            plot_images(generator.predict(images[:5]), title=\"Generated Images\")\n\n# Train the model\ntrain_gan(generator, discriminator, gan, images, EPOCHS, BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NLP Model for Text-to-Image\ntext_to_image = pipeline(\"text-to-image-generation\")\n\ndef generate_image_from_text(prompt):\n    print(f\"Generating image for prompt: {prompt}\")\n    results = text_to_image(prompt)\n    image_data = results[0]['image']\n    plt.imshow(image_data)\n    plt.axis('off')\n    plt.title(f\"Generated for: {prompt}\")\n    plt.show()\n\n# Example\ngenerate_image_from_text(\"A cozy room with a fireplace and a modern couch.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Upload Widget\nupload_widget = widgets.FileUpload(accept='image/*', multiple=False)\ndisplay(upload_widget)\n\ndef on_image_upload(change):\n    if upload_widget.value:\n        file_info = next(iter(upload_widget.value.values()))\n        img_data = file_info['content']\n        with open(\"uploaded_image.jpg\", \"wb\") as f:\n            f.write(img_data)\n        print(\"Image uploaded successfully!\")\n\nupload_widget.observe(on_image_upload, names='value')\n\n# User Preferences\nroom_style = widgets.Dropdown(options=['Modern', 'Vintage', 'Industrial'], description='Style:')\nroom_color = widgets.ColorPicker(value='#ffffff', description='Color:')\ndisplay(room_style, room_color)\n\n# Generate Design\nuploaded_image_path = \"uploaded_image.jpg\"\n\ndef generate_design_based_on_preferences():\n    if os.path.exists(uploaded_image_path):\n        img = cv2.imread(uploaded_image_path)\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0\n        img = np.expand_dims(img, axis=0)\n        styled_img = generator.predict(img)[0]\n        plt.imshow(styled_img)\n        plt.axis('off')\n        plt.title(f\"Design in {room_style.value} Style with Color {room_color.value}\")\n        plt.show()\n    else:\n        print(\"Upload an image to proceed.\")\n\ngenerate_design_based_on_preferences()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save Generator model\ngenerator.save(SAVE_PATH)\nprint(f\"Generator model saved to {SAVE_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}